{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Задание по варианту:</h4> comp.os.ms-windows.misc, rec.sport.baseball, sci.crypt, sci.med, sci.space <br>(Название категорий статей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text From: ajpat@IASTATE.EDU (Amy J Patterson)\n",
      "Subject: Twins Games :)\n",
      "Reply-To: ajpat@IASTATE.EDU (Amy J Patterson)\n",
      "Organization: Iowa State University\n",
      "Lines: 4\n",
      "\n",
      "Does anyone know if the Twins games are broadcast in\n",
      "good ole Ames Iowa??????????????\n",
      "\n",
      "Thanks all.\n",
      "\n",
      "category: 1\n"
     ]
    }
   ],
   "source": [
    "categories = ['comp.os.ms-windows.misc', 'rec.sport.baseball', 'sci.crypt', 'sci.med', 'sci.space']\n",
    "ngAll = fetch_20newsgroups(subset='all', categories=categories)\n",
    "print('text', ngAll.data[0]) #Один вариант по данным\n",
    "print('category:', ngAll.target[0]) #Целевая категория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Параметры обучения</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01 # Шаг приближения для оптимизатора\n",
    "training_epochs = 10 # Количество эпох для обучени\n",
    "batch_size = 150 # Размер минибатча - маленькая порция данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Параметры нейронной сети</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 500 # Скрытый слой 1\n",
    "n_hidden_2 = 300  # Скрытый слой 2\n",
    "n_hidden_3 = 100  # Скрытый слой 3\n",
    "n_classes = len(categories) # Количество выходных классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подготовки данных воспользуемся функцией векторизации текстов TfidfVectorizer из библиотеки scikit-learn модуля sklearn.feature_extraction.text\n",
    "<br>CountVectorizer показал себя очень плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "data = vectorizer.fit_transform(ngAll.data).toarray() # Преобразуем данные в виды массивов\n",
    "inputDim = len(vectorizer.get_feature_names()) # Размер входного слоя\n",
    "\n",
    "xTrain = data[:2500] # Срез данных. Берем 2500 первых единиц данных\n",
    "yTrain = ngAll.target[:2500] # Срез данных. Берем 2500 первых единиц данных\n",
    "xTest = data[2500:] # Срез данных. Берем после 2500 \n",
    "yTest = ngAll.target[2500:] # Срез данных. Берем после 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(input_shape=(inputDim)),\n",
    "        layers.Dense(n_hidden_1, activation='relu'),\n",
    "        layers.Dense(n_hidden_2, activation='relu'),\n",
    "        layers.Dense(n_hidden_3, activation='relu'),\n",
    "        layers.Dense(n_classes, activation='relu')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile (\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 - 5s - loss: 0.9225 - accuracy: 0.6308\n",
      "Epoch 2/10\n",
      "17/17 - 4s - loss: 0.6386 - accuracy: 0.7960\n",
      "Epoch 3/10\n",
      "17/17 - 4s - loss: 0.6437 - accuracy: 0.7956\n",
      "Epoch 4/10\n",
      "17/17 - 4s - loss: 0.6387 - accuracy: 0.7940\n",
      "Epoch 5/10\n",
      "17/17 - 4s - loss: 0.6293 - accuracy: 0.7976\n",
      "Epoch 6/10\n",
      "17/17 - 4s - loss: 0.6368 - accuracy: 0.7976\n",
      "Epoch 7/10\n",
      "17/17 - 4s - loss: 0.6299 - accuracy: 0.7992\n",
      "Epoch 8/10\n",
      "17/17 - 4s - loss: 0.6303 - accuracy: 0.7988\n",
      "Epoch 9/10\n",
      "17/17 - 4s - loss: 0.6429 - accuracy: 0.7964\n",
      "Epoch 10/10\n",
      "17/17 - 4s - loss: 0.6272 - accuracy: 0.7988\n",
      "77/77 - 2s - loss: 0.8143 - accuracy: 0.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8143064379692078, 0.7588884234428406]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, batch_size=batch_size, epochs=training_epochs, verbose=2)\n",
    "model.evaluate(xTest, yTest, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
